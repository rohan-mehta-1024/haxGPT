
Step: 0 | Average Train Loss: 4.25 | Average Val Loss: 4.24
step: 1, loss: 4.2598 time: 1779.43ms, mfu: 0.00%
step: 2, loss: 4.2342 time: 2107.50ms, mfu: 0.00%
step: 3, loss: 4.2246 time: 1864.40ms, mfu: 0.00%
step: 4, loss: 4.2469 time: 51.02ms, mfu: 0.00%
step: 5, loss: 4.2479 time: 50.61ms, mfu: 0.01%
step: 6, loss: 4.2494 time: 50.97ms, mfu: 0.01%
step: 7, loss: 4.2315 time: 50.17ms, mfu: 0.01%
step: 8, loss: 4.2516 time: 51.89ms, mfu: 0.01%
step: 9, loss: 4.2386 time: 50.09ms, mfu: 0.01%
step: 10, loss: 4.2476 time: 50.00ms, mfu: 0.01%
step: 11, loss: 4.2152 time: 49.73ms, mfu: 0.01%
step: 12, loss: 4.2488 time: 50.50ms, mfu: 0.02%
step: 13, loss: 4.2148 time: 49.49ms, mfu: 0.02%
step: 14, loss: 4.2218 time: 50.09ms, mfu: 0.02%
step: 15, loss: 4.2330 time: 50.69ms, mfu: 0.02%
step: 16, loss: 4.2028 time: 49.20ms, mfu: 0.02%
step: 17, loss: 4.2078 time: 50.56ms, mfu: 0.02%
step: 18, loss: 4.2010 time: 50.21ms, mfu: 0.02%
step: 19, loss: 4.2122 time: 49.97ms, mfu: 0.02%
step: 20, loss: 4.2150 time: 49.90ms, mfu: 0.02%
step: 21, loss: 4.1795 time: 50.41ms, mfu: 0.02%
step: 22, loss: 4.1844 time: 50.75ms, mfu: 0.02%
step: 23, loss: 4.1906 time: 50.67ms, mfu: 0.02%
step: 24, loss: 4.1869 time: 50.57ms, mfu: 0.02%
step: 25, loss: 4.1658 time: 51.31ms, mfu: 0.02%
step: 26, loss: 4.1612 time: 50.77ms, mfu: 0.02%
step: 27, loss: 4.1267 time: 53.40ms, mfu: 0.02%
step: 28, loss: 4.1208 time: 53.09ms, mfu: 0.02%
step: 29, loss: 4.1219 time: 52.88ms, mfu: 0.02%
step: 30, loss: 4.1002 time: 53.25ms, mfu: 0.02%
step: 31, loss: 4.1210 time: 53.30ms, mfu: 0.02%
step: 32, loss: 4.0797 time: 53.73ms, mfu: 0.02%
step: 33, loss: 4.0704 time: 51.79ms, mfu: 0.02%
step: 34, loss: 4.0647 time: 52.38ms, mfu: 0.02%
step: 35, loss: 4.0411 time: 54.02ms, mfu: 0.02%
step: 36, loss: 4.0326 time: 51.80ms, mfu: 0.02%
step: 37, loss: 4.0375 time: 51.12ms, mfu: 0.02%
step: 38, loss: 3.9810 time: 50.62ms, mfu: 0.02%
step: 39, loss: 3.9668 time: 50.64ms, mfu: 0.02%
step: 40, loss: 3.9775 time: 50.87ms, mfu: 0.02%
step: 41, loss: 3.9307 time: 52.03ms, mfu: 0.02%
step: 42, loss: 3.9028 time: 53.50ms, mfu: 0.02%
step: 43, loss: 3.8927 time: 54.44ms, mfu: 0.02%
step: 44, loss: 3.8540 time: 54.22ms, mfu: 0.02%
step: 45, loss: 3.8268 time: 55.57ms, mfu: 0.02%
step: 46, loss: 3.8078 time: 54.96ms, mfu: 0.02%
step: 47, loss: 3.7684 time: 53.90ms, mfu: 0.02%
step: 48, loss: 3.7656 time: 53.68ms, mfu: 0.02%
step: 49, loss: 3.6819 time: 53.46ms, mfu: 0.02%
step: 50, loss: 3.7213 time: 50.38ms, mfu: 0.02%
step: 51, loss: 3.6784 time: 50.41ms, mfu: 0.02%
step: 52, loss: 3.6094 time: 50.18ms, mfu: 0.02%
step: 53, loss: 3.6265 time: 49.41ms, mfu: 0.02%
step: 54, loss: 3.5613 time: 49.18ms, mfu: 0.02%
step: 55, loss: 3.5508 time: 50.06ms, mfu: 0.02%
step: 56, loss: 3.5860 time: 50.35ms, mfu: 0.03%
step: 57, loss: 3.5125 time: 49.80ms, mfu: 0.03%
step: 58, loss: 3.4767 time: 50.33ms, mfu: 0.03%
step: 59, loss: 3.5098 time: 51.49ms, mfu: 0.03%
step: 60, loss: 3.4816 time: 52.00ms, mfu: 0.03%
step: 61, loss: 3.4807 time: 52.82ms, mfu: 0.03%
step: 62, loss: 3.5814 time: 53.21ms, mfu: 0.03%
step: 63, loss: 3.4861 time: 51.87ms, mfu: 0.03%
step: 64, loss: 3.4440 time: 50.42ms, mfu: 0.03%
step: 65, loss: 3.4122 time: 51.20ms, mfu: 0.03%
step: 66, loss: 3.4985 time: 50.59ms, mfu: 0.03%
step: 67, loss: 3.4637 time: 50.14ms, mfu: 0.03%
step: 68, loss: 3.4471 time: 49.77ms, mfu: 0.03%
step: 69, loss: 3.4336 time: 50.48ms, mfu: 0.03%
step: 70, loss: 3.4429 time: 50.67ms, mfu: 0.03%
step: 71, loss: 3.4151 time: 50.56ms, mfu: 0.03%
step: 72, loss: 3.3831 time: 52.56ms, mfu: 0.03%
step: 73, loss: 3.3857 time: 52.84ms, mfu: 0.03%
step: 74, loss: 3.3087 time: 53.90ms, mfu: 0.03%
step: 75, loss: 3.3735 time: 53.02ms, mfu: 0.03%
step: 76, loss: 3.4535 time: 53.28ms, mfu: 0.02%
step: 77, loss: 3.3811 time: 53.63ms, mfu: 0.02%
step: 78, loss: 3.3866 time: 53.23ms, mfu: 0.02%
step: 79, loss: 3.4379 time: 53.15ms, mfu: 0.02%
step: 80, loss: 3.3283 time: 52.33ms, mfu: 0.02%
step: 81, loss: 3.3553 time: 52.62ms, mfu: 0.02%
step: 82, loss: 3.3417 time: 51.19ms, mfu: 0.02%
step: 83, loss: 3.3187 time: 49.91ms, mfu: 0.02%
step: 84, loss: 3.3052 time: 50.53ms, mfu: 0.02%
step: 85, loss: 3.3435 time: 49.61ms, mfu: 0.03%
step: 86, loss: 3.2717 time: 52.82ms, mfu: 0.03%
step: 87, loss: 3.2844 time: 52.07ms, mfu: 0.02%
step: 88, loss: 3.4176 time: 50.69ms, mfu: 0.03%
step: 89, loss: 3.3010 time: 53.33ms, mfu: 0.02%
step: 90, loss: 3.3082 time: 55.40ms, mfu: 0.02%
step: 91, loss: 3.3382 time: 55.08ms, mfu: 0.02%
step: 92, loss: 3.2848 time: 57.26ms, mfu: 0.02%
step: 93, loss: 3.1984 time: 58.94ms, mfu: 0.02%
step: 94, loss: 3.2491 time: 59.36ms, mfu: 0.02%
step: 95, loss: 3.2223 time: 58.33ms, mfu: 0.02%
step: 96, loss: 3.2971 time: 55.67ms, mfu: 0.02%
step: 97, loss: 3.1598 time: 55.03ms, mfu: 0.02%
step: 98, loss: 3.2386 time: 53.42ms, mfu: 0.02%
step: 99, loss: 3.2224 time: 50.82ms, mfu: 0.02%
step: 100, loss: 3.1710 time: 50.08ms, mfu: 0.02%
step: 101, loss: 3.2439 time: 50.43ms, mfu: 0.02%
step: 102, loss: 3.2520 time: 50.45ms, mfu: 0.02%
step: 103, loss: 3.2018 time: 50.35ms, mfu: 0.02%
step: 104, loss: 3.1263 time: 50.34ms, mfu: 0.02%
step: 105, loss: 3.0990 time: 49.64ms, mfu: 0.02%
step: 106, loss: 3.1346 time: 50.00ms, mfu: 0.02%
step: 107, loss: 3.1420 time: 50.49ms, mfu: 0.02%
step: 108, loss: 3.1345 time: 50.12ms, mfu: 0.03%
step: 109, loss: 3.0971 time: 50.80ms, mfu: 0.03%
Traceback (most recent call last):
  File "/Users/rohanmehta/Desktop/ML Projects/GPT_nano/train.py", line 419, in <module>
    main()
  File "/Users/rohanmehta/anaconda3/envs/jax/lib/python3.11/site-packages/draccus/argparsing.py", line 182, in wrapper_inner
    response = fn(cfg, *args, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/rohanmehta/Desktop/ML Projects/GPT_nano/train.py", line 416, in main
    trainer.train()
  File "/Users/rohanmehta/Desktop/ML Projects/GPT_nano/train.py", line 381, in train
    self.state, loss = self.train_step() #self.train_step(self.state)
                       ^^^^^^^^^^^^^^^^^
  File "/Users/rohanmehta/Desktop/ML Projects/GPT_nano/train.py", line 300, in train_step
    model, opt_state, loss = self.update(self.model, self.opt_state, data_keys)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/rohanmehta/anaconda3/envs/jax/lib/python3.11/site-packages/equinox/_jit.py", line 206, in __call__
    return self._call(False, args, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/rohanmehta/anaconda3/envs/jax/lib/python3.11/site-packages/equinox/_module.py", line 875, in __call__
    return self.__func__(self.__self__, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/rohanmehta/anaconda3/envs/jax/lib/python3.11/site-packages/equinox/_jit.py", line 200, in _call
    out = self._cached(dynamic_donate, dynamic_nodonate, static)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/rohanmehta/anaconda3/envs/jax/lib/python3.11/site-packages/haliax/core.py", line 129, in tree_unflatten
    @classmethod
KeyboardInterrupt
Traceback (most recent call last):
  File "/Users/rohanmehta/Desktop/ML Projects/GPT_nano/train.py", line 419, in <module>
    main()
  File "/Users/rohanmehta/anaconda3/envs/jax/lib/python3.11/site-packages/draccus/argparsing.py", line 182, in wrapper_inner
    response = fn(cfg, *args, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/rohanmehta/Desktop/ML Projects/GPT_nano/train.py", line 416, in main
    trainer.train()
  File "/Users/rohanmehta/Desktop/ML Projects/GPT_nano/train.py", line 381, in train
    self.state, loss = self.train_step() #self.train_step(self.state)
                       ^^^^^^^^^^^^^^^^^
  File "/Users/rohanmehta/Desktop/ML Projects/GPT_nano/train.py", line 300, in train_step
    model, opt_state, loss = self.update(self.model, self.opt_state, data_keys)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/rohanmehta/anaconda3/envs/jax/lib/python3.11/site-packages/equinox/_jit.py", line 206, in __call__
    return self._call(False, args, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/rohanmehta/anaconda3/envs/jax/lib/python3.11/site-packages/equinox/_module.py", line 875, in __call__
    return self.__func__(self.__self__, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/rohanmehta/anaconda3/envs/jax/lib/python3.11/site-packages/equinox/_jit.py", line 200, in _call
    out = self._cached(dynamic_donate, dynamic_nodonate, static)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/rohanmehta/anaconda3/envs/jax/lib/python3.11/site-packages/haliax/core.py", line 129, in tree_unflatten
    @classmethod
KeyboardInterrupt